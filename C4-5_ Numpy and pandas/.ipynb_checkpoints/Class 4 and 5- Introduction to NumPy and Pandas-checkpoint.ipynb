{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `numpy` and `pandas` to hold and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Two of the most useful libraries for working with scientific data are `numpy` and `pandas`. \n",
    "\n",
    "`Numpy` is a library of math functions we need to do data analysis. \n",
    "\n",
    "`Numpy` also introduces a new object for holding groups of variables: n-dimensional arrays of data. Within `numpy` they're referred to as ndarrays, but I'll just call them arrays for this class. \n",
    "\n",
    "We'll start by introducing you to arrays and `numpy` functions, why you might want to use them, and how they work. Later we'll cover `pandas`, a \"wrapper\" for `numpy` arrays that makes them simpler to use, and `scipy`, which adds more complex mathematical and statistical functions to python using arrays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's upgrade! Adding libraries to python\n",
    "\n",
    "First we need to import the libraries we want to use. This is the same process you used for the last homework to add new functions to python, but these packages add hundreds of new functions\n",
    "\n",
    "When we import these libraries we can give them an alias, which is easier to remember and type. The ones used below are common for these packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the description of numpy.\n",
    "# Remember, almost every function and library has a small help file\n",
    "\n",
    "#np?\n",
    "\n",
    "# Try hitting tab after the period to see all the numpy function options\n",
    "#np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `numpy` has several sub-libraries that group together functions by category, like np.random for getting random numbers, np.linalg for doing linear algebra, etc. We will mostly use np.random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy arrays: a new thing to hold other things\n",
    "\n",
    "NumPy arrays are essentially lists that have two important restrictions:\n",
    "\n",
    " - An array can only hold one type of data\n",
    " - Arrays are unmutable: you **can** change the contents, but you **can't** change the size of the array or the data type\n",
    "     - To \"add\" to an array you have to make a new array that is a copy plus the new data\n",
    " \n",
    "Why would we want a list with extra restrictions? The short answer is speed. The computer only needs to check the type of data once for the array, not once for each variable. This adds up when you have huge arrays like the results of an 'omics' experiment. \n",
    "\n",
    "There are a number of ways to make numpy arrays. You can import data from text files (covered later), you can convert a list to an array, or you can use one of the numpy functions that builds some basic array types useful for data analysis.\n",
    "\n",
    "Let's look at two new functions from NumPy for making arrays: `np.arange()` and `np.zeroes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# The numpy function arange(start, stop, step) gives you an array of values\n",
    "# between the start and stop (not including the stop) incremented by step\n",
    "# The default step is 1\n",
    "a = np.arange(0,10)\n",
    "\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(10,)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Let's check the size of our new array\n",
    "\n",
    "# We can do this with len(), like we did with lists\n",
    "print (len (a))\n",
    "\n",
    "# Remember how an object is a collection of variables and methods?\n",
    "# In addition to the variables contained by the array, \n",
    "# numpy arrays store variables _about_ the array\n",
    "\n",
    "print(a.shape) # we'll come back to this when we make arrays with more dimensions\n",
    "print(a.size)\n",
    "\n",
    "# Note that these aren't methods, so you don't use parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0 1 2]\n",
      "[2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 0  1  2 99  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "# We can get data from the array just like we did with lists and tuples with square brackets and slicing\n",
    "print(a[3])\n",
    "print(a[0:3])\n",
    "print(a[2:])\n",
    "\n",
    "# We use square brackets to assign new values to our array\n",
    "print(a)\n",
    "a[3]=99\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math operations on arrays\n",
    "Math operators ($+, -, *, /$) work on arrays by acting on each element or variable in the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   3   6 297  12  15  18  21  24  27]\n",
      "[  3   4   5 102   7   8   9  10  11  12]\n"
     ]
    }
   ],
   "source": [
    "print (a*3)\n",
    "print (a+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2 99  4  5  6  7  8  9]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "[ 0.   1.1  2.2 99.3  4.4  5.5  6.6  7.7  8.8  9.9]\n"
     ]
    }
   ],
   "source": [
    "# You can use operators with two arrays\n",
    "b = np.arange(0,1,0.1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(b+a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2 99  4  5  6  7  8  9]\n",
      "[0, 1, 2, 99, 4, 5, 6, 7, 8, 9]\n",
      "[  0   3   6 297  12  15  18  21  24  27]\n",
      "[0, 1, 2, 99, 4, 5, 6, 7, 8, 9, 0, 1, 2, 99, 4, 5, 6, 7, 8, 9, 0, 1, 2, 99, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Notice operators work with differently with arrays and lists\n",
    "# You can convert an array to a list using the method ndarray.tolist()\n",
    "# Convert a to a_list and then multiply both by three\n",
    "\n",
    "a_list = a.tolist()\n",
    "print (a)\n",
    "print(a_list)\n",
    "print(a*3)\n",
    "print (a_list*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False  True False]\n",
      " [False False False  True  True]]\n",
      "[[False False False  True False]\n",
      " [False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "# You can also use boolean operators on arrays\n",
    "# That gives us an array of True and False values\n",
    "print(a >= 8) # Which values are greater than or equal to 8\n",
    "print(a == 99) # Which values are equal to 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding dimensions\n",
    "\n",
    "So far all of the arrays we've worked with have been one dimensional. NumPy arrays can be any number of dimensions. What does that mean? It just means we are keeping track of that many different variables for each sample. \n",
    "\n",
    "M. tuberculosis has ~4,000 genes. If we do an RNAseq experiment with three samples and measure the expression of each gene for each sample, we are generating 4,000 dimensional data. We could plot the expression of one gene on a line, two genes on a grid, three genes in 3D, maybe show data for another few genes by mapping that to the size and color of the marker. \n",
    "\n",
    "Let's start by making a two dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2 99  4]\n",
      " [ 5  6  7  8  9]]\n",
      "a is still: [[ 0  1  2 99  4]\n",
      " [ 5  6  7  8  9]]\n",
      "[[ 0  1  2 99  4]\n",
      " [ 5  6  7  8  9]]\n"
     ]
    }
   ],
   "source": [
    "# First, let's reshape our 1D array from above using the ndarray.reshape() method\n",
    "# We know from a couple cells above that a is 10 variables long\n",
    "# Reshape that to a 2 by 5 table\n",
    "print(a.reshape(2,5))\n",
    "\n",
    "# Note that didn't change the shape of a!\n",
    "print('a is still:',a)\n",
    "\n",
    "# If you don't store the reshaped array it simply shows us the table... sometimes thats all we want\n",
    "# Otherwise you can store that view in another variable, or overwrite the existing variable\n",
    "a = a.reshape(2,5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an array with three dimensions, each of length three\n",
    "a_3d = np.arange(1,28,1).reshape(3,3, 3)\n",
    "print(a_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3  6  9]\n",
      "  [12 15 18]\n",
      "  [21 24 27]]\n",
      "\n",
      " [[30 33 36]\n",
      "  [39 42 45]\n",
      "  [48 51 54]]\n",
      "\n",
      " [[57 60 63]\n",
      "  [66 69 72]\n",
      "  [75 78 81]]]\n",
      "[[[  1   4   9]\n",
      "  [ 16  25  36]\n",
      "  [ 49  64  81]]\n",
      "\n",
      " [[100 121 144]\n",
      "  [169 196 225]\n",
      "  [256 289 324]]\n",
      "\n",
      " [[361 400 441]\n",
      "  [484 529 576]\n",
      "  [625 676 729]]]\n"
     ]
    }
   ],
   "source": [
    "# We can use mathematical operators just like we did with the 1D arrays\n",
    "print(a_3d*3)\n",
    "print(a_3d**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is:\n",
      " [[ 0  1  2 99  4]\n",
      " [ 5  6  7  8  9]]\n",
      "a_3d is:\n",
      " [[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[10 11 12]\n",
      "  [13 14 15]\n",
      "  [16 17 18]]\n",
      "\n",
      " [[19 20 21]\n",
      "  [22 23 24]\n",
      "  [25 26 27]]]\n"
     ]
    }
   ],
   "source": [
    "# As before you can you can get specific values or ranges of values using square brackets and slices\n",
    "print(\"a is:\\n\",a)\n",
    "print(\"a_3d is:\\n\",a_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the fourth value in the first column from a\n",
    "a[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the second row of values from a\n",
    "# Remember, if you want all of the values use a colon\n",
    "a[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  7],\n",
       "       [10, 13, 16],\n",
       "       [19, 22, 25]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first layer of a_3d\n",
    "a_3d[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Think of two ways to get the last layer of a_3d\n",
    "a_3d[:,:,2] == a_3d[:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for modifying arrays\n",
    "We've already seen ndarray.reshape for changing the structure of our data. We can also divide arrays with np.split() and add data with np.append() or np.stack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]]), array([[[10, 11, 12],\n",
       "         [13, 14, 15],\n",
       "         [16, 17, 18]]]), array([[[19, 20, 21],\n",
       "         [22, 23, 24],\n",
       "         [25, 26, 27]]])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The np.split() function will split an array into equal sized chunks\n",
    "# You can specify if you want to break up the array by rows, columns, sheets, etc.\n",
    "np.split(a_3d, 3, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, 99,  4,  5,  6,  7,  8,  9,  1,  2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember that NumPy arrays are immutable, so any change we make is just a \"view\" until we make a copy\n",
    "# For instance, we can add data to an array using np.append, but that won't change the original array\n",
    "np.append(a, (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could spend a lot more time looking at how to get subsets out of NumPy arrays, but all of this is much easier with `pandas`, which we will cover next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy functions make arrays shine\n",
    "On their own, ndarrays are a useful tool. But NumPy and SciPy give you a library of functions that work with arrays, and that is where they become essential for data analysis. I'll cover a few of the most useful right now, but we will see many more functions for working with arrays as the class goes on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magic functions\n",
    "The first function is actually not part of NumPy. Python has a set of \"magic\" commands that let you have a small set of commands that work on memory and the operating system. Not surprisingly, you can easily cause things to crash doing that, so magic commands try to limit your ability to do damage by only giving you a few powerful functions. All magic functions start with a $%$ symbol. We will run into a few more of these later, but for now I just want to show you one really useful magic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "a          ndarray    2x5: 10 elems, type `int32`, 40 bytes\n",
      "a_3d       ndarray    3x3x3: 27 elems, type `int32`, 108 bytes\n",
      "a_list     list       n=10\n",
      "b          ndarray    10: 10 elems, type `float64`, 80 bytes\n",
      "np         module     <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd         module     <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt        module     <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n"
     ]
    }
   ],
   "source": [
    "# This will show us every variable in memory\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "a          ndarray    2x5: 10 elems, type `int32`, 40 bytes\n",
      "a_3d       ndarray    3x3x3: 27 elems, type `int32`, 108 bytes\n",
      "b          ndarray    10: 10 elems, type `float64`, 80 bytes\n"
     ]
    }
   ],
   "source": [
    "# This will show us every variable in memory that has the data type 'ndarray'\n",
    "%whos ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random number generators\n",
    "\n",
    "Random numbers are a good way of simulating expected results or sampling a random subset of data. \n",
    "\n",
    "We can generate random numbers using the functions in the np.random sub-library. These numbers can be taken from a uniform distribution (all numbers equally possible) or from a normal distribution (a 'bell-shape' centered on the mean) or many other distributions we won't cover here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start by setting a random seed so that all our random variables match\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 8, 4, 1, 8, 4, 6, 8])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A random integer with randint(start, stop(not included), number of values desired)\n",
    "np.random.randint(1, 11, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 8]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "# Random integers between 0 and 10 in a 2 by 2 array\n",
    "print(np.random.randint(0, 10, size=[2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72595568 0.89711026 0.88708642]\n"
     ]
    }
   ],
   "source": [
    "# Three random floating-point number between 0 and 1\n",
    "print(np.random.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.30714275 -1.60748323  0.18463386  0.25988279  0.78182287]]\n"
     ]
    }
   ],
   "source": [
    "# Normal distribution with mean=0 and variance=1 in a 1 by 5 array\n",
    "print(np.random.randn(1, 5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o' 'i' 'a' 'i' 'a' 'u' 'e' 'e' 'e' 'i']\n",
      "['o' 'a' 'o' 'a' 'e' 'o' 'o' 'o' 'o' 'o']\n"
     ]
    }
   ],
   "source": [
    "# Pick 10 items from a given list, with equal probability\n",
    "print(np.random.choice(['a', 'e', 'i', 'o', 'u'], size=10))  \n",
    "\n",
    "# Pick 10 items from a given list with a predefined probability 'p'\n",
    "print(np.random.choice(['a', 'e', 'i', 'o', 'u'], size=10, p=[0.3, .1, 0.1, 0.4, 0.1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85   0.357 -0.693  0.9    0.307]\n",
      " [ 1.626  1.259 -1.658 -1.12   1.495]\n",
      " [ 1.831 -0.063  0.352  3.833 -1.775]\n",
      " [ 2.188 -0.809 -0.871  4.395  3.302]\n",
      " [ 4.068  6.527  0.105  3.41  -1.551]]\n"
     ]
    }
   ],
   "source": [
    "# Let's make a 5 by 5 matrix of random numbers from the normal distribution\n",
    "# And let's be a bit fancy- keep the mean at zero but\n",
    "# use a for loop and fill in the first row with sd =1, the second with sd = 2, etc.\n",
    "\n",
    "normarray = np.zeros ((5,5))\n",
    "\n",
    "for row in np.arange(5):\n",
    "    randrow = np.random.randn(5)*(row + 1)\n",
    "    normarray[row, :] = randrow\n",
    "\n",
    "normarray = normarray.round(3)\n",
    "print(normarray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built in methods for NumPy arrays \n",
    "Lastly lets look at some of the methods that every NumPy array has. We've already used ndarray.tolist() and nda.reshape().\n",
    "\n",
    "Now we will learn how to get the average, min, max, or median of ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1306000000000003\n",
      "[ 2.1126  1.4542 -0.553   2.2836  0.3556]\n",
      "[0.3442 0.3204 0.8356 1.641  2.5118]\n"
     ]
    }
   ],
   "source": [
    "# The nda.mean() gives you the mean of the whole array\n",
    "print(normarray.mean())\n",
    "\n",
    "# You can specify if you want to average the rows (axis=0) or columns (axis=1)\n",
    "print(normarray.mean(axis=0))\n",
    "print(normarray.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9   1.626 3.833 4.395 6.527]\n",
      "[-0.693 -1.658 -1.775 -0.871 -1.551]\n"
     ]
    }
   ],
   "source": [
    "# You get min, max, or median the same way\n",
    "print(normarray.max(axis=1))\n",
    "print(normarray.min(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85 ,  1.626,  1.831,  2.188,  4.068],\n",
       "       [ 0.357,  1.259, -0.063, -0.809,  6.527],\n",
       "       [-0.693, -1.658,  0.352, -0.871,  0.105],\n",
       "       [ 0.9  , -1.12 ,  3.833,  4.395,  3.41 ],\n",
       "       [ 0.307,  1.495, -1.775,  3.302, -1.551]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also transpose an array using array.T()\n",
    "normarray.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework for Class 4\n",
    "\n",
    "Let's use NumPy arrays and functions in a demo experiment. \n",
    "\n",
    "We have a new drug, excitin (tm), that we think acts by blocking fatty acid synthesis. If we are right, genes in that pathway are likely induced to try and compensate. We are going to check if we are right by looking at expression of those genes in the presence and absence of excitin. \n",
    "\n",
    "We don't have a good idea *when* we expect to see the FA synthesis pathway induced, so we are sampling every 8 hours for three days in the presence and absence of excitin. We will measure the expression of six genes at each time point, three FA biosynthesis genes and three control genes that we don't expect to see changed. \n",
    "\n",
    "While the experiment is running lets use dummy data to set up an analysis pipeline.\n",
    "\n",
    "For the homework you need to:\n",
    "> 1. Make an array containing all of the time points in this experiment\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a08e61859ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Pass np.arange() the start, stop (not included), and step size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msample_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's set up an array of sampling times using a new function: np.arange()\n",
    "# Pass np.arange() the start, stop (not included), and step size\n",
    "\n",
    "sample_times = np.arange(0, 3*24+1, 8)\n",
    "\n",
    "print(sample_times)\n",
    "print(type(sample_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make an array to hold all of our results when we get them\n",
    "# Let's say we're going to use qRT-PCR to measure expression of five genes at each time point\n",
    "# We can use np.zeroes((tuple)) to set up an array filled with zeroes,\n",
    "# where tuple is the size of the array we want, 10 by 5\n",
    "\n",
    "array_size = (10, 5)\n",
    "data_table = np.zeros (array_size)\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a table of data that assumes the null hypothesis, i.e. we won't see any expression changes. If that's the case we will have a mean of zero (no change) with some noise that follows a normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pandas` for tidy data management\n",
    "\n",
    "Prior to `pandas` python was a useful language for pulling together data and preparing it for data analysis, but `R` (another programming language) was more popular for analysis and modeling. One advantage of `R` is the way it handles arrays of data using a type of object called a DataFrame that had a lot of useful methods. Think of a DataFrame as an Excel spreadsheet in computer memory. \n",
    "\n",
    "`Pandas` brings DataFrames to python. \n",
    "\n",
    "Let's import some data to work with. `Pandas` provides simple tools for importing from Excel, csv, or any other common data format. Here we are going to use the `read_csv` command to pull in a table of RNAseq data from a [melanoma study from 2017](https://www.nature.com/articles/s41467-017-02353-y) published in Nature Communications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` arrays let you slice and manipulate data and perform lots of mathematical operations on those arrays. `Pandas` builds on that functionality by focusing on rigidly defined lists (Series) and 2D tables (DataFrames aka \"panel data\", whence comes `pandas`). `Pandas` also makes data import and manipulation simpler and more intuitive than `numpy`. However in exchange for being simpler to write and read, `pandas` can be slower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have data already you can import it directly from a text file like a comma seperated values, or csv, file. `Pandas` makes this easy. But in `numpy`, well...\n",
    "\n",
    "**DO NOT TRY TO UNDERSTAND THIS CODE** \n",
    "This is the code for importing csv files with numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_birthday.txt', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} works in the {row[\"department\"]} department, and was born in {row[\"birthday month\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much easier to do in `pandas`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these packages by typing in the alias followed by a '.' and a method name. We'll start by importing a table of expression data using `read_csv` and a table of metadata using `read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is tab separated and the first column has the gene names\n",
    "# Remember that most things in python are zero-indexed, so the first\n",
    "# column is index 0\n",
    "df = pd.read_csv('data\\GSE88741-expression.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` introduces two new ways of collecting variables:\n",
    "\n",
    " - Series: A named list of values, all of the same type\n",
    " - DataFrame: Basically an Excel spreadsheet in computer memory. Each column is a different Series of data, and each row is a separate observation or sample.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the imported data\n",
    "# The number of rows and columns in a DataFrame can be found at df.shape\n",
    "print (df.shape)\n",
    "\n",
    "# Let's take a look at the top of `df` using df.head()\n",
    "# Input a number between the parentheses to indicate how many lines you want to see- 5 is default\n",
    "print (df.head())\n",
    "\n",
    "# Note: Why don't we need parentheses after `df.shape`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() shows a quick statistics summary of your data\n",
    "# round() limits the number of significant digits\n",
    "# You can chain together functions like we do here with round\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a large dataset, so lets take a small random sample to work with\n",
    "# the sample() method randomly selects a number of rows or columns from a larger DataFrame\n",
    "# We are setting the random_state here so that we all use the same random genes\n",
    "df_sample = df.sample(100, axis = 0, random_state = 333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Dimensions of DataFrame:\",df_sample.shape)\n",
    "print (df_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring in the metadata from an excel spreadsheet\n",
    "meta = pd.read_excel(\"data/GSE88741-metadata.xlsx\", index_col=1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's extract the Sample Titles and use them to replace the ugly GSM names\n",
    "columns = meta.index\n",
    "print (type(columns))\n",
    "df_sample.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we set the column names above\n",
    "# We can use that command to show us index and column names as well\n",
    "print(df_sample.index)\n",
    "print(df_sample.columns)\n",
    "print(df_sample.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and sorting\n",
    "Getting subsets of data out of `pandas` DataFrames is done primarily in one of two ways.\n",
    "If you want to search for row and column names, you use .loc()\n",
    "You can instead use the indexes to select the data you want using .iloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort by the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.UACC_62_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can send our DataFrame into a numpy array\n",
    "# ndarrays can only be one type of data, so if we added any metadata\n",
    "# this would convert to whatever data type works for all data types present\n",
    "\n",
    "nda = df.to_numpy()\n",
    "type(nda)\n",
    "#nda.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
